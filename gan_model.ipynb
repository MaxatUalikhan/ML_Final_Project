{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.layers import LeakyReLU, UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('archive 3\\sign_mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27450</th>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "      <td>234</td>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27451</th>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27452</th>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27453</th>\n",
       "      <td>17</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27454</th>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>194</td>\n",
       "      <td>214</td>\n",
       "      <td>203</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>209</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27455 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          3     107     118     127     134     139     143     146     150   \n",
       "1          6     155     157     156     156     156     157     156     158   \n",
       "2          2     187     188     188     187     187     186     187     188   \n",
       "3          2     211     211     212     212     211     210     211     210   \n",
       "4         13     164     167     170     172     176     179     180     184   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27450     13     189     189     190     190     192     193     193     193   \n",
       "27451     23     151     154     157     158     160     161     163     164   \n",
       "27452     18     174     174     174     174     174     175     175     174   \n",
       "27453     17     177     181     184     185     187     189     190     191   \n",
       "27454     23     179     180     180     180     182     181     182     183   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         153  ...       207       207       207       207       206   \n",
       "1         158  ...        69       149       128        87        94   \n",
       "2         187  ...       202       201       200       199       198   \n",
       "3         210  ...       235       234       233       231       230   \n",
       "4         185  ...        92       105       105       108       133   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27450     193  ...       132       165        99        77        52   \n",
       "27451     166  ...       198       198       198       198       198   \n",
       "27452     173  ...       121       196       209       208       206   \n",
       "27453     191  ...       119        56        27        58       102   \n",
       "27454     182  ...       108       132       170       194       214   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           206       206       204       203       202  \n",
       "1           163       175       103       135       149  \n",
       "2           199       198       195       194       195  \n",
       "3           226       225       222       229       163  \n",
       "4           163       157       163       164       179  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27450       200       234       200       222       225  \n",
       "27451       196       195       195       195       194  \n",
       "27452       204       203       202       200       200  \n",
       "27453        79        47        64        87        93  \n",
       "27454       203       197       205       209       215  \n",
       "\n",
       "[27455 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = 0\n",
    "discriminator = 0\n",
    "images = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1126/1126 [00:00<00:00, 1579.03it/s]\n",
      "100%|██████████| 1010/1010 [00:00<00:00, 1592.44it/s]\n",
      "100%|██████████| 1144/1144 [00:00<00:00, 1664.41it/s]\n",
      "100%|██████████| 1196/1196 [00:00<00:00, 1597.48it/s]\n",
      "100%|██████████| 957/957 [00:00<00:00, 1666.05it/s]\n",
      "100%|██████████| 1204/1204 [00:00<00:00, 1620.49it/s]\n",
      "100%|██████████| 1090/1090 [00:00<00:00, 1744.69it/s]\n",
      "100%|██████████| 1013/1013 [00:00<00:00, 1689.31it/s]\n",
      "100%|██████████| 1162/1162 [00:00<00:00, 1662.34it/s]\n",
      "100%|██████████| 1114/1114 [00:00<00:00, 1594.18it/s]\n",
      "100%|██████████| 1241/1241 [00:00<00:00, 1633.64it/s]\n",
      "100%|██████████| 1055/1055 [00:00<00:00, 1442.32it/s]\n",
      "100%|██████████| 1151/1151 [00:00<00:00, 1683.52it/s]\n",
      "100%|██████████| 1196/1196 [00:00<00:00, 1687.66it/s]\n",
      "100%|██████████| 1088/1088 [00:00<00:00, 1672.01it/s]\n",
      "100%|██████████| 1279/1279 [00:00<00:00, 1566.60it/s]\n",
      "100%|██████████| 1294/1294 [00:00<00:00, 1551.17it/s]\n",
      "100%|██████████| 1199/1199 [00:00<00:00, 1691.91it/s]\n",
      "100%|██████████| 1186/1186 [00:00<00:00, 1697.07it/s]\n",
      "100%|██████████| 1161/1161 [00:00<00:00, 1638.44it/s]\n",
      "100%|██████████| 1082/1082 [00:00<00:00, 1545.92it/s]\n",
      "100%|██████████| 1225/1225 [00:00<00:00, 1726.64it/s]\n",
      "100%|██████████| 1164/1164 [00:00<00:00, 1674.29it/s]\n",
      "100%|██████████| 1118/1118 [00:00<00:00, 1688.37it/s]\n"
     ]
    }
   ],
   "source": [
    "new_df = {}\n",
    "\n",
    "for label, label_df in df.groupby('label'):\n",
    "    images = []\n",
    "    for index, row in tqdm(label_df.iterrows(), total=len(label_df)):\n",
    "        pixels = row.drop('label')\n",
    "        images.append(pixels.to_numpy().reshape((28,28, 1)))\n",
    "\n",
    "    new_df[label] = np.array(images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will generate 28px square images.\n"
     ]
    }
   ],
   "source": [
    "GENERATE_RES = 1 # Generation resolution factor \n",
    "# (1=32, 2=64, 3=96, 4=128, etc.)\n",
    "GENERATE_SQUARE = 28 # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 1\n",
    "\n",
    "# Preview image \n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 5\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(seed_size):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(7 * 7 * 128,activation=\"relu\",input_dim=seed_size))\n",
    "  model.add(Reshape((7,7, 128)))\n",
    "\n",
    "  # model.add(UpSampling2D())\n",
    "  # model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "  # model.add(BatchNormalization(momentum=0.8))\n",
    "  # model.add(Activation(\"relu\"))\n",
    "\n",
    "  model.add(UpSampling2D())\n",
    "  model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(Activation(\"relu\"))\n",
    "   \n",
    "  model.add(UpSampling2D())\n",
    "  model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(Activation(\"relu\"))\n",
    "\n",
    "  model.add(UpSampling2D(size=(GENERATE_RES,GENERATE_RES)))\n",
    "  model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(Activation(\"relu\"))\n",
    "\n",
    "  model.add(Conv2D(filters = 1 , kernel_size=3, padding=\"same\"))\n",
    "  model.add(Activation(\"tanh\"))\n",
    "\n",
    "  return model\n",
    "\n",
    "  # input = Input(shape=(seed_size, ))\n",
    "  # genereated_image = model(input)\n",
    "\n",
    "  # return Model(input, genereated_image)\n",
    "\n",
    "\n",
    "def build_discriminator(image_shape):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, \n",
    "                     padding=\"same\"))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "  model.add(BatchNormalization(momentum=0.8))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "  return model\n",
    "\n",
    "  # input_image = Input(shape = image_shape)\n",
    "\n",
    "  # validaty = model(input_image)\n",
    "\n",
    "  # return Model(input_image, validaty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt,noise, label):\n",
    "  image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 1), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "  generated_images = generator.predict(noise)\n",
    "\n",
    "  generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "  image_count = 0\n",
    "  for row in range(PREVIEW_ROWS):\n",
    "      for col in range(PREVIEW_COLS):\n",
    "        r = row * (GENERATE_SQUARE+PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "        c = col * (GENERATE_SQUARE+PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] \\\n",
    "            = generated_images[image_count] * 255\n",
    "        image_count += 1\n",
    "\n",
    "          \n",
    "  output_path = os.path.join('gan_images',f'{label}')\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "  \n",
    "  filename = os.path.join(output_path,f\"{cnt}.png\")\n",
    "  plt.imshow(image_array, cmap = 'gray')\n",
    "  plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6272"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 7 * 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import BinaryCrossentropy\n",
    "cross_entropy = BinaryCrossentropy()\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "  seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(seed, training=True)\n",
    "\n",
    "    real_output = discriminator(images, training=True)\n",
    "    fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "    gen_loss = generator_loss(fake_output)\n",
    "    disc_loss = discriminator_loss(real_output, fake_output)\n",
    "    \n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "  return gen_loss,disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hms_string(sec_elapsed):\n",
    "    \"\"\"Converts a time in seconds to a string of hours, minutes, and seconds.\"\"\"\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h}:{m:>02}:{s:>05.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_images, epochs, batch_size, label):\n",
    "  fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, \n",
    "                                       SEED_SIZE))\n",
    "  start = time.time()\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    gen_loss_list = []\n",
    "    disc_loss_list = []\n",
    "\n",
    "    for i in tqdm(range(0, len(train_images), batch_size)):\n",
    "\n",
    "      image_batch = train_images[i:i+batch_size]\n",
    "      @tf.function\n",
    "      def train_step(images):\n",
    "        seed = tf.random.normal([BATCH_SIZE, SEED_SIZE])\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "          generated_images = generator(seed, training=True)\n",
    "\n",
    "          real_output = discriminator(images, training=True)\n",
    "          fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "          gen_loss = generator_loss(fake_output)\n",
    "          disc_loss = discriminator_loss(real_output, fake_output)\n",
    "          \n",
    "\n",
    "          gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "          gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "          generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "          discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "          return gen_loss,disc_loss\n",
    "          \n",
    "      t = train_step(image_batch)\n",
    "\n",
    "      gen_loss_list.append(t[0])\n",
    "      disc_loss_list.append(t[1])\n",
    "\n",
    "    g_loss = sum(gen_loss_list) / len(gen_loss_list)\n",
    "    d_loss = sum(disc_loss_list) / len(disc_loss_list)\n",
    "\n",
    "    epoch_elapsed = time.time()-epoch_start\n",
    "    print (f'Epoch {epoch+1}, gen loss={g_loss},disc loss={d_loss},'\\\n",
    "           f' {hms_string(epoch_elapsed)}')\n",
    "    save_images(epoch,fixed_seed, label)\n",
    "\n",
    "  elapsed = time.time()-start\n",
    "  print (f'Training time: {hms_string(elapsed)}')\n",
    "\n",
    "  generator.save(f\"models/{label}_image_generator.h5\")\n",
    "  discriminator.save(f\"models/{label}_image_discriminator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training gan for 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 4/36 [00:08<01:06,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function train.<locals>.train_step at 0x000001C4E9DA89D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 5/36 [00:10<01:06,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function train.<locals>.train_step at 0x000001C4EABC5D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:13<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, gen loss=2.6943869590759277,disc loss=0.4680771231651306, 0:01:13.27\n",
      "1/1 [==============================] - 0s 262ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:17<00:00,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, gen loss=3.395922899246216,disc loss=0.4593951404094696, 0:01:17.76\n",
      "1/1 [==============================] - 0s 211ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:12<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, gen loss=3.6028311252593994,disc loss=0.5188815593719482, 0:01:12.69\n",
      "1/1 [==============================] - 0s 163ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:20<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, gen loss=2.87688946723938,disc loss=0.9844840168952942, 0:01:20.29\n",
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:12<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, gen loss=2.5370736122131348,disc loss=1.0754268169403076, 0:01:12.91\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:12<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, gen loss=2.582186698913574,disc loss=0.8990635275840759, 0:01:12.23\n",
      "1/1 [==============================] - 0s 129ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [01:12<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, gen loss=2.692110300064087,disc loss=0.7683954238891602, 0:01:12.55\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 164ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:10<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, gen loss=2.9332926273345947,disc loss=0.6234901547431946, 0:01:10.41\n",
      "1/1 [==============================] - 0s 128ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [01:06<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, gen loss=3.114832878112793,disc loss=0.5242533683776855, 0:01:06.03\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 138ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:05<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, gen loss=3.1480977535247803,disc loss=0.5444872975349426, 0:01:05.92\n",
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [01:12<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, gen loss=3.2751331329345703,disc loss=0.509730339050293, 0:01:12.76\n",
      "1/1 [==============================] - 0s 138ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [01:38<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, gen loss=3.290142297744751,disc loss=0.46902841329574585, 0:01:38.66\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:25<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, gen loss=3.1943976879119873,disc loss=0.49840396642684937, 0:01:25.37\n",
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [02:36<00:00,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, gen loss=3.1837124824523926,disc loss=0.46541541814804077, 0:02:36.88\n",
      "1/1 [==============================] - 0s 142ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [01:09<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, gen loss=3.308637857437134,disc loss=0.4462612569332123, 0:01:09.84\n",
      "1/1 [==============================] - 0s 132ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 36/36 [01:06<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, gen loss=3.2377700805664062,disc loss=0.507010281085968, 0:01:06.32\n",
      "1/1 [==============================] - 0s 175ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:17<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, gen loss=3.341498613357544,disc loss=0.47430816292762756, 0:01:17.25\n",
      "1/1 [==============================] - 0s 156ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [01:37<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, gen loss=3.1658518314361572,disc loss=0.4819848835468292, 0:01:37.24\n",
      "1/1 [==============================] - 1s 687ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [05:09<00:00,  8.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, gen loss=3.0824007987976074,disc loss=0.5456675291061401, 0:05:09.13\n",
      "1/1 [==============================] - 0s 300ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [04:54<00:00,  8.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, gen loss=3.2675468921661377,disc loss=0.49150168895721436, 0:04:54.27\n",
      "1/1 [==============================] - 0s 247ms/step\n",
      "Training time: 0:34:31.08\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "training gan for 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 25/38 [03:46<01:57,  9.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m generator \u001b[39m=\u001b[39m build_generator(SEED_SIZE)\n\u001b[0;32m      8\u001b[0m discriminator \u001b[39m=\u001b[39m build_discriminator(image_shape)\n\u001b[1;32m----> 9\u001b[0m train(images, \u001b[39m20\u001b[39;49m, BATCH_SIZE, label)\n",
      "Cell \u001b[1;32mIn[25], line 36\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_images, epochs, batch_size, label)\u001b[0m\n\u001b[0;32m     33\u001b[0m     discriminator_optimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradients_of_discriminator, discriminator\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m gen_loss,disc_loss\n\u001b[1;32m---> 36\u001b[0m t \u001b[39m=\u001b[39m train_step(image_batch)\n\u001b[0;32m     38\u001b[0m gen_loss_list\u001b[39m.\u001b[39mappend(t[\u001b[39m0\u001b[39m])\n\u001b[0;32m     39\u001b[0m disc_loss_list\u001b[39m.\u001b[39mappend(t[\u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:928\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    925\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    926\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 928\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    929\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    930\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    931\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    932\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:749\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    747\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 749\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn    \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    750\u001b[0m     \u001b[39m.\u001b[39m_get_concrete_function_internal_garbage_collected(\n\u001b[0;32m    751\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    753\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    754\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:162\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 162\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:157\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    155\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:360\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m    358\u001b[0m   args, kwargs \u001b[39m=\u001b[39m generalized_func_key\u001b[39m.\u001b[39m_placeholder_value()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(args, kwargs)\n\u001b[0;32m    362\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:284\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    279\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m    280\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m    281\u001b[0m ]\n\u001b[0;32m    282\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m    283\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 284\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    285\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    287\u001b[0m         args,\n\u001b[0;32m    288\u001b[0m         kwargs,\n\u001b[0;32m    289\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    290\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m    291\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m    292\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    293\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m    294\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    295\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    296\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1283\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1281\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1283\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1285\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:645\u001b[0m, in \u001b[0;36mFunction._compiler_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    642\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    643\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    644\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 645\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    646\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1258\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1258\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1259\u001b[0m       original_func,\n\u001b[0;32m   1260\u001b[0m       args,\n\u001b[0;32m   1261\u001b[0m       kwargs,\n\u001b[0;32m   1262\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1263\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1264\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1265\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1266\u001b[0m       ))\n\u001b[0;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileb_vsvcww.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[1;34m(images)\u001b[0m\n\u001b[0;32m     15\u001b[0m gen_loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(generator_loss), (ag__\u001b[39m.\u001b[39mld(fake_output),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m disc_loss \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(discriminator_loss), (ag__\u001b[39m.\u001b[39mld(real_output), ag__\u001b[39m.\u001b[39mld(fake_output)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 17\u001b[0m gradients_of_generator \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(gen_tape)\u001b[39m.\u001b[39;49mgradient, (ag__\u001b[39m.\u001b[39;49mld(gen_loss), ag__\u001b[39m.\u001b[39;49mld(generator)\u001b[39m.\u001b[39;49mtrainable_variables), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     18\u001b[0m gradients_of_discriminator \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(disc_tape)\u001b[39m.\u001b[39mgradient, (ag__\u001b[39m.\u001b[39mld(disc_loss), ag__\u001b[39m.\u001b[39mld(discriminator)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     19\u001b[0m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(generator_optimizer)\u001b[39m.\u001b[39mapply_gradients, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mzip\u001b[39m), (ag__\u001b[39m.\u001b[39mld(gradients_of_generator), ag__\u001b[39m.\u001b[39mld(generator)\u001b[39m.\u001b[39mtrainable_variables), \u001b[39mNone\u001b[39;00m, fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[0;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[1;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[0;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1106\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1107\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1108\u001b[0m           output_gradients))\n\u001b[0;32m   1109\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1110\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1112\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1114\u001b[0m     flat_targets,\n\u001b[0;32m   1115\u001b[0m     flat_sources,\n\u001b[0;32m   1116\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1117\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1118\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1121\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1678\u001b[0m, in \u001b[0;36m_SelectGradV2\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1676\u001b[0m y_shape \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mshape(y)\n\u001b[0;32m   1677\u001b[0m \u001b[39m# Reduce away broadcasted leading dims.\u001b[39;00m\n\u001b[1;32m-> 1678\u001b[0m reduce_y, _ \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49mbroadcast_gradient_args(y_shape, output_shape)\n\u001b[0;32m   1679\u001b[0m gy \u001b[39m=\u001b[39m math_ops\u001b[39m.\u001b[39mreduce_sum(gy, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, axis\u001b[39m=\u001b[39mreduce_y)\n\u001b[0;32m   1680\u001b[0m gy \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mreshape(gy, y_shape)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:947\u001b[0m, in \u001b[0;36mbroadcast_gradient_args\u001b[1;34m(s0, s1, name)\u001b[0m\n\u001b[0;32m    945\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    948\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mBroadcastGradientArgs\u001b[39;49m\u001b[39m\"\u001b[39;49m, s0\u001b[39m=\u001b[39;49ms0, s1\u001b[39m=\u001b[39;49ms1, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    949\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m    950\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:795\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    790\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    791\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    792\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    793\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    794\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    796\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    797\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    799\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    800\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    803\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:749\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    747\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    748\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 749\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    750\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    751\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3798\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3795\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3796\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3797\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3798\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3799\u001b[0m       node_def,\n\u001b[0;32m   3800\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3801\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3802\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3803\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3804\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3805\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3806\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3807\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3808\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2106\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2103\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2105\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2106\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1937\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1935\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1936\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 1937\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(c_graph,\n\u001b[0;32m   1938\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1939\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1940\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1941\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator_optimizer = Adam(1.5e-4,0.5)\n",
    "discriminator_optimizer = Adam(1.5e-4,0.5)\n",
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE, 1)\n",
    "\n",
    "for label in np.sort(df.label.unique())[2:]:\n",
    "    \n",
    "    print('training gan for', label)\n",
    "    images = new_df[label]\n",
    "    generator = build_generator(SEED_SIZE)\n",
    "    discriminator = build_discriminator(image_shape)\n",
    "    train(images, 20, BATCH_SIZE, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
